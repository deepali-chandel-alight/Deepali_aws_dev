{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1afdd7e-ed33-4072-a407-b833f43e2263",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boto3==1.28.21\n",
      "  Using cached boto3-1.28.21-py3-none-any.whl (135 kB)\n",
      "Collecting botocore<1.32.0,>=1.31.21 (from boto3==1.28.21)\n",
      "  Using cached botocore-1.31.50-py3-none-any.whl (11.2 MB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3==1.28.21) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from boto3==1.28.21) (0.6.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.10/site-packages (from botocore<1.32.0,>=1.31.21->boto3==1.28.21) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.10/site-packages (from botocore<1.32.0,>=1.31.21->boto3==1.28.21) (1.26.14)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.32.0,>=1.31.21->boto3==1.28.21) (1.16.0)\n",
      "Installing collected packages: botocore, boto3\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.29.132\n",
      "    Uninstalling botocore-1.29.132:\n",
      "      Successfully uninstalled botocore-1.29.132\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.26.132\n",
      "    Uninstalling boto3-1.26.132:\n",
      "      Successfully uninstalled boto3-1.26.132\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.27.132 requires botocore==1.29.132, but you have botocore 1.31.50 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed boto3-1.28.21 botocore-1.31.50\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting botocore==1.31.21\n",
      "  Using cached botocore-1.31.21-py3-none-any.whl (11.1 MB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from botocore==1.31.21) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.10/site-packages (from botocore==1.31.21) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.10/site-packages (from botocore==1.31.21) (1.26.14)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore==1.31.21) (1.16.0)\n",
      "Installing collected packages: botocore\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.31.50\n",
      "    Uninstalling botocore-1.31.50:\n",
      "      Successfully uninstalled botocore-1.31.50\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awscli 1.27.132 requires botocore==1.29.132, but you have botocore 1.31.21 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed botocore-1.31.21\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting bert-score\n",
      "  Using cached bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "Requirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from bert-score) (2.0.0)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from bert-score) (2.0.1)\n",
      "Collecting transformers>=3.0.0 (from bert-score)\n",
      "  Using cached transformers-4.33.2-py3-none-any.whl (7.6 MB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bert-score) (1.23.5)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from bert-score) (2.28.2)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /opt/conda/lib/python3.10/site-packages (from bert-score) (4.64.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from bert-score) (3.7.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from bert-score) (23.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2023.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (4.5.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (1.11.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.1.2)\n",
      "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers>=3.0.0->bert-score)\n",
      "  Using cached huggingface_hub-0.17.2-py3-none-any.whl (294 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (5.4.1)\n",
      "Collecting regex!=2019.12.17 (from transformers>=3.0.0->bert-score)\n",
      "  Using cached regex-2023.8.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (771 kB)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers>=3.0.0->bert-score)\n",
      "  Using cached tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "Collecting safetensors>=0.3.1 (from transformers>=3.0.0->bert-score)\n",
      "  Using cached safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (4.39.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->bert-score) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->bert-score) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->bert-score) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->bert-score) (2023.5.7)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers>=3.0.0->bert-score) (2023.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->bert-score) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.0.0->bert-score) (1.3.0)\n",
      "Installing collected packages: tokenizers, safetensors, regex, huggingface-hub, transformers, bert-score\n",
      "Successfully installed bert-score-0.3.13 huggingface-hub-0.17.2 regex-2023.8.8 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.33.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting evaluate\n",
      "  Using cached evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
      "Collecting datasets>=2.0.0 (from evaluate)\n",
      "  Using cached datasets-2.14.5-py3-none-any.whl (519 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.23.5)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.6)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.0.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.28.2)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.64.1)\n",
      "Collecting xxhash (from evaluate)\n",
      "  Using cached xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2023.5.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.17.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (23.1)\n",
      "Collecting responses<0.19 (from evaluate)\n",
      "  Using cached responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (12.0.0)\n",
      "Collecting aiohttp (from datasets>=2.0.0->evaluate)\n",
      "  Using cached aiohttp-3.8.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (5.4.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2023.5.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.2.0)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets>=2.0.0->evaluate)\n",
      "  Using cached multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets>=2.0.0->evaluate)\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets>=2.0.0->evaluate)\n",
      "  Using cached yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets>=2.0.0->evaluate)\n",
      "  Using cached frozenlist-1.4.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (225 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets>=2.0.0->evaluate)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Installing collected packages: xxhash, multidict, frozenlist, async-timeout, yarl, responses, aiosignal, aiohttp, datasets, evaluate\n",
      "Successfully installed aiohttp-3.8.5 aiosignal-1.3.1 async-timeout-4.0.3 datasets-2.14.5 evaluate-0.4.0 frozenlist-1.4.0 multidict-6.0.4 responses-0.18.0 xxhash-3.3.0 yarl-1.9.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: spacy in /opt/conda/lib/python3.10/site-packages (3.5.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /opt/conda/lib/python3.10/site-packages (from spacy) (8.1.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.1.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.4.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (4.64.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.23.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.28.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.10.7)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy) (65.6.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.5.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy) (2.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
      "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
      "Collecting en-core-web-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from en-core-web-sm==3.5.0) (3.5.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.64.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.23.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.28.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.7)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (65.6.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2023.5.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.2)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.5.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-2.2.2-py3-none-any.whl\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.33.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.64.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.0.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.15.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.23.5)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.10.1)\n",
      "Collecting nltk (from sentence-transformers)\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Collecting sentencepiece (from sentence-transformers)\n",
      "  Using cached sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.17.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.12.0)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.5.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.28.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (1.11.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.8.8)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.3.3)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk->sentence-transformers) (8.1.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence-transformers) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.5.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
      "Installing collected packages: sentencepiece, nltk, sentence-transformers\n",
      "Successfully installed nltk-3.8.1 sentence-transformers-2.2.2 sentencepiece-0.1.99\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install boto3==1.28.21\n",
    "!python3 -m pip install botocore==1.31.21\n",
    "!pip install bert-score\n",
    "!pip install evaluate\n",
    "!pip install spacy\n",
    "!python -m spacy download en\n",
    "\n",
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c173888-94d0-4c39-8557-ef4f19b88dec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install torch>=1.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc4b3611-99c1-44cf-b4c1-4fe9d7234f49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pwd\n",
    "# !python3 -m pip install boto3-1.28.21-py3-none-any.whl\n",
    "# !python3 -m pip install botocore-1.31.21-py3-none-any.whl\n",
    "# !pip install bert-score\n",
    "# !pip install evaluate\n",
    "# !pip install spacy\n",
    "# !python -m spacy download en\n",
    "\n",
    "# !pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cccf955-002d-4d65-a9b9-5b19fc6d69fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.33.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.17.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.8.8)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b58e1f6-4e4a-4d53-9203-0a63bb5b1c15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate==0.20.3\n",
      "  Using cached accelerate-0.20.3-py3-none-any.whl (227 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.20.3) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.20.3) (23.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.20.3) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate==0.20.3) (5.4.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.20.3) (2.0.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate==0.20.3) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate==0.20.3) (4.5.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate==0.20.3) (1.11.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate==0.20.3) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate==0.20.3) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->accelerate==0.20.3) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->accelerate==0.20.3) (1.3.0)\n",
      "Installing collected packages: accelerate\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 0.19.0\n",
      "    Uninstalling accelerate-0.19.0:\n",
      "      Successfully uninstalled accelerate-0.19.0\n",
      "Successfully installed accelerate-0.20.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate==0.20.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f197568-426b-404c-b5de-223c9c9e24a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import time\n",
    "import spacy\n",
    "import numpy as np\n",
    "import json\n",
    "from evaluate import load\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fdbea30-4e55-4b13-9395-8087dff1dab8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "# bedrock = boto3.client(service_name='bedrock',region_name='us-east-1',endpoint_url='https://bedrock.us-east-1.amazonaws.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d312741-1a9b-44e3-9dcb-3191753bc0fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# bedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f50d8ea0-080e-44f5-a761-e77c4b2f1086",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question=\"\\n\\n How are primary care office visits covered?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c1630e5-48db-4246-9d99-294779d6d8e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_data=\"|Common Medical Event|Services You May Need|What You Will Pay, Network Provider|What You Will Pay, Out-of-Network Provider|Limitations, Exceptions, & Other Important Information| |:-:|:-:|:-:|:-:|:-:| | If you visit a health care provider's office or clinic|Primary care visit to treat an injury or illness|$20 / visit|Not Covered|None| | If you visit a health care provider's office or clinic|Specialist visit|$20 / visit|Not Covered|None| | If you visit a health care provider's office or clinic|Preventive care/ screening/ immunization|No Charge|Not Covered|You may have to pay for services that aren't preventive. Ask your provider if the services needed are preventive. Then check what your plan will pay for.| |If have test you a|Diagnostic test (x- ray, blood work)|No Charge|Not Covered|None| |If have test you a|Imaging (CT/PET scans, MRI's)|No Charge|Not Covered|None| |If need you drugs to treat your illness or condition More information about prescription drug coverage is available at www.kp.org/formulary |Generic drugs (Tier 1)|Retail: $10 / prescription; Mail order: $20 / prescription|Not Covered|Up to a 30-day supply retail or 100-day supply mail order. Subject to formulary guidelines. No Charge for Contraceptives.| |If need you drugs to treat your illness or condition More information about prescription drug coverage is available at www.kp.org/formulary |Preferred brand drugs (Tier 2)|Retail: $20 / prescription; Mail order: $40 / prescription|Not Covered|Up to a 30-day supply retail or 100-day supply mail order. Subject to formulary guidelines. No Charge for Contraceptives.| |If need you drugs to treat your illness or condition More information about prescription drug coverage is available at www.kp.org/formulary |Non-preferred brand drugs (Tier 2)|Same as preferred brand drugs|Not Covered|The cost sharing for non-preferred brand drugs under this plan aligns with the cost sharing for preferred brand drugs (Tier 2), when approved through the formulary exception process.| |If need you drugs to treat your illness or condition More information about prescription drug coverage is available at www.kp.org/formulary |Specialty drugs (Tier 4)|$20 / prescription|Not Covered|Up to a 30-day supply retail. Subject to formulary guidelines.| |If you have outpatient surgery|Facility fee (e.g., ambulatory surgery center)|$20 / procedure|Not Covered|None| |If you have outpatient surgery|Physician/surgeon fees|No Charge|Not Covered|Physician/surgeon fees are included in the Facility fee.| | If you need immediate medical attention |Emergency room care|$50 / visit|$50 / visit|None| | If you need immediate medical attention |Emergency medical transportation|$50 / trip|$50 / trip|None| | If you need immediate medical attention |Urgent care|$20 / visit|Not Covered|Non-Plan providers covered when temporarily outside the service area: $20 / visit.| |If you have a hospital stay|Facility fee (e.g., hospital room)|$500 / admission|Not Covered|None| |If you have a hospital stay|Physician/surgeon fee|No Charge|Not Covered|Physician/surgeon fees are included in the Facility fee.| |If you need mental health, behavioral substance health, or abuse services|Outpatient services|$20 / individual visit. No Charge for other outpatient services|Not Covered|Mental / Behavioral Health: $10 / group visit; Substance Abuse: $5 / group visit.| |If you need mental health, behavioral substance health, or abuse services|Inpatient services|$500 / admission|Not Covered|None| |If you are pregnant |Office visits|No Charge|Not covered|Depending on the type of services, a copayment, coinsurance, or deductible may apply. Maternity care may include tests and services described elsewhere in the SBC (i.e. ultrasound).| |If you are pregnant |Childbirth/delivery professional services|No Charge|Not Covered|Professional services are included in the Facility services.| |If you are pregnant |Childbirth/delivery facility services|$500 / admission|Not Covered|None| | If you need help have recovering or other special health needs |Home health care|No Charge|Not Covered|Up to 2 hours maximum / visit, up to 3 visits maximum / day, up to 100 visits maximum / year.| | If you need help have recovering or other special health needs |Rehabilitation services|Inpatient: $500 / admission; Outpatient: $20 / visit|Not Covered|None| | If you need help have recovering or other special health needs |Habilitation services|$20 / visit|Not Covered|None| | If you need help have recovering or other special health needs |Skilled nursing care|No Charge|Not Covered|Up to 100 days maximum / benefit period.| | If you need help have recovering or other special health needs |Durable medical equipment|20% coinsurance|Not Covered|Requires prior authorization.| | If you need help have recovering or other special health needs |Hospice service|No Charge|Not Covered|None| | If your child needs dental or eye care|Children's eye exam|No Charge|Not Covered|None| | If your child needs dental or eye care|Children's glasses|Not Covered|Not Covered|None| | If your child needs dental or eye care|Children's dental check-up|Not Covered|Not Covered|None|\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d5f99c8-06c2-49fc-a3e4-c9b750b57b12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Trial Cell to run Bedrock\n",
    "prompt_input=prompt_data+\"\\n\\nQuestion: \"+question+\"\\nAnswer: \"\n",
    "#print(prompt_input)\n",
    "\n",
    "body = json.dumps({\"prompt\": prompt_input, \"max_tokens_to_sample\": 120,\"temperature\":0})\n",
    "# modelId = 'anthropic.claude-v2' # change this to use a different version from the model provider\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "\n",
    "# response = bedrock.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "# print(response.get('body').read())\n",
    "#response_body = json.loads(response.get('body').read())\n",
    "\n",
    "#print(response_body.get('completion'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e385a90d-f3eb-4d05-b401-c22cc70f6cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e0d2427-5776-4bcb-87d8-bb1ed93f69d6",
   "metadata": {},
   "source": [
    "Refactored code of Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31e3111d-563f-48ba-84e5-a03a78f369e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.model import Model\n",
    "from sagemaker.predictor import Predictor\n",
    "\n",
    "\n",
    "bertscore = load(\"bertscore\")\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f68748e-ef37-4e46-ac7c-6e158da08dd3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sagemaker.jumpstart.model import JumpStartModel\\nmodel_id=\\'huggingface-llm-falcon-7b-bf16\\'\\nmy_model = JumpStartModel(model_id=model_id, instance_type=\"ml.g5.2xlarge\")\\npredictor = my_model.deploy()'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sagemaker.jumpstart.model import JumpStartModel\n",
    "model_id='huggingface-llm-falcon-7b-bf16'\n",
    "my_model = JumpStartModel(model_id=model_id, instance_type=\"ml.g5.2xlarge\")\n",
    "predictor = my_model.deploy()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7806b7ed-04a6-4d90-b07d-8d10ba6d5fcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def stopword_verb_removal(sentence,nlp):    \n",
    "    \n",
    "    doc = nlp(sentence)\n",
    "\n",
    "    new_text=[]\n",
    "    for token in doc:\n",
    "        if token.pos_==\"VERB\" or token.is_stop:# or token.sent_start>0 or token.is_sent_end:\n",
    "            '''print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "                token.shape_, token.is_alpha, token.is_stop, token.sent_start, token.is_sent_end)'''\n",
    "            continue\n",
    "        else:\n",
    "            new_text.append(token.text)\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99b82480-b415-4449-98dd-0a82178e280c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_prompt(text_for_prompt,question,prompt_type):\n",
    "    if prompt_type==1:\n",
    "        prompt_input_text=text_for_prompt+\"\\n\\nQuestion: \"+question+\"\\nAnswer: \"\n",
    "    elif prompt_type==2:\n",
    "        prompt_input_text=\"Question: \"+question+\"\\nKnowledge: \"+text_for_prompt+\"\\n\\nAnswer: \"\n",
    "    else:\n",
    "        prompt_input_text=text_for_prompt+\"\\n\\nQuestion: \"+question+\"\\nAnswer: \"\n",
    "    \n",
    "    return prompt_input_text\n",
    "\n",
    "def model_response(predictor,text_for_prompt,model_params,accept,contentType,question,prompt_type):\n",
    "    '''prompt_input=prompt_text+\"\\n\\nQuestion: \"+question+\"\\nAnswer: \"\n",
    "    payload = {\n",
    "    \"inputs\": prompt_input,\n",
    "    \"parameters\": {\n",
    "        \"do_sample\": True,\n",
    "        \"top_p\": 0.999999,\n",
    "        \"temperature\": 0.01,\n",
    "        \"max_new_tokens\": 120,\n",
    "        #\"stop\": [\"<|endoftext|>\", \"</s>\"]\n",
    "    }\n",
    "}'''\n",
    "    prompt_input_text=format_prompt(text_for_prompt,question,prompt_type)\n",
    "    payload={\"inputs\":prompt_input_text,\"parameters\":model_params}\n",
    "    try:\n",
    "        response = predictor.predict(json.dumps(payload).encode('utf-8'),{\n",
    "            \"ContentType\": contentType,\n",
    "            \"Accept\": accept,\n",
    "        },)\n",
    "        #print(response[0][\"generated_text\"])\n",
    "    except Exception as e:\n",
    "        error_message=getattr(e, 'message', repr(e))\n",
    "        error_message_list.append(error_message)\n",
    "        #print(error_message)\n",
    "        #Exception due to token, reducing the token size.        \n",
    "        token_count=error_message[204+len(\"1024 tokens. Given: \"):204+len(\"1024 tokens. Given: \")+4]\n",
    "        \n",
    "        if token_count.isdigit():\n",
    "            pass\n",
    "        else:\n",
    "            input_text_token_position=error_message.find('must be <=',0)\n",
    "            max_token_position=error_message.find('Given: ',input_text_token_position)\n",
    "            token_count=error_message[max_token_position+len('Given: '):max_token_position+len('Given: ')+4]\n",
    "            message_token_counts_list.append(token_count)\n",
    "            # print(\"Inside Condition Token Count\",token_count)\n",
    "        # print(\"token_count\",token_count)\n",
    "        token_removal_count=np.round((int(token_count)-1024)*0.4)\n",
    "        # print(\"Token Count\",token_count, type(token_count),\"Token Removal\",token_removal_count,type(token_removal_count))\n",
    "        \n",
    "        new_prompt_text=text_for_prompt.split(\" \")\n",
    "        #print(\"Type Prompt Text\",type(prompt_text))\n",
    "        #print(\"New Prompt Text\",type(new_prompt_text))\n",
    "        # print(\"token_removal_count\", token_removal_count)\n",
    "        new_prompt_text=\" \".join(new_prompt_text[:-int(token_removal_count)])\n",
    "        response=model_response(predictor,new_prompt_text,model_params,accept,contentType,question,prompt_type)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b46379f-3813-4ae4-bdb3-28a813a9eac0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# def generate_predictions(text_for_prompt,model_params,modelID,accept,contentType,model_type,question,prompt_type):\n",
    "#     if model_type==\"jumpstart\":\n",
    "#         predictor=Predictor(endpoint_name=modelID)\n",
    "#         start_time_invoke_model=time.time()    \n",
    "#         response = model_response(predictor,text_for_prompt,model_params,accept,contentType,question,prompt_type)\n",
    "#         end_time_invoke_model=time.time()\n",
    "#         answer=eval(response.decode('utf-8'))[0]['generated_text']\n",
    "#     return answer,start_time_invoke_model,end_time_invoke_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73521d9f-5aab-4e09-9bdb-903454c8cedf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_predictions(text_for_prompt,model_params,modelID,accept,contentType,model_type,question,prompt_type):\n",
    "    if model_type==\"jumpstart\":\n",
    "        if modelID ==\"hf-llm-falcon-40b-instruct-bf16-2023-09-19-01-54-52-766\":\n",
    "            predictor=Predictor(endpoint_name=modelID)\n",
    "        elif modelID ==\"meta-textgeneration-llama-2-13b-f-2023-09-19-02-06-14-205\":\n",
    "            predictor=Predictor(endpoint_name=modelID, custom_attributes=\"accept_eula=true\")\n",
    "        start_time_invoke_model=time.time()    \n",
    "        response = model_response(predictor,text_for_prompt,model_params,accept,contentType,question,prompt_type)\n",
    "        end_time_invoke_model=time.time()\n",
    "        answer=eval(response.decode('utf-8'))[0]['generated_text']\n",
    "    return answer,start_time_invoke_model,end_time_invoke_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0622894c-aa73-4844-9c84-3eabe66cf4f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#modelID for jumpstart is endpoint_name\n",
    "#not_smename_key_list is list like [\"Predictions\",\"context\"]\n",
    "def add_predictions(masterfile_json,model_params,modelID,accept,contentType,prediction_tag,not_smename_key_list,model_type,nlp,prompt_type):\n",
    "    \n",
    "    bscore_precision_embed,bscore_precision_display,bscore_recall=-2,-2,-2\n",
    "    sscore_precision_embed_refined,sscore_precision_display_refined,sscore_recall_refined=-2,-2,-2\n",
    "    human_answer_refined, high_precision_embed_answer_refined,\\\n",
    "                high_precision_display_answer_refined,high_recall_answer_refined=\"NA\",\"NA\",\"NA\",\"NA\"\n",
    "    for question in masterfile_json:\n",
    "        print(question)\n",
    "        for filenames in [file for file in masterfile_json[question].keys() if file not in [\"associated_queries\",\"information_need\"]]:\n",
    "            print(filenames)\n",
    "            if type(masterfile_json[question][filenames][\"context\"][\"high precision\"])!=list:\n",
    "                prompt_precision_embed_data=masterfile_json[question][filenames][\"context\"][\"high precision\"][\"embed\"]\n",
    "                prompt_precision_display_data=masterfile_json[question][filenames][\"context\"][\"high precision\"][\"display\"]\n",
    "            else:\n",
    "                prompt_precision_embed_data=(\"\\n\").join([precision_embed_data[\"embed\"] for precision_embed_data in masterfile_json[question][filenames][\"context\"][\"high precision\"]])\n",
    "                prompt_precision_display_data=(\"\\n\").join([precision_embed_data[\"display\"] for precision_embed_data in masterfile_json[question][filenames][\"context\"][\"high precision\"]])\n",
    "            \n",
    "            high_precision_embed_answer,start_time_precision_embed_invoke_model,end_time_precision_embed_invoke_model=generate_predictions(text_for_prompt=prompt_precision_embed_data,model_params=model_params,modelID=modelID,accept=accept,contentType=contentType,model_type=model_type,question=question,prompt_type=prompt_type)\n",
    "            \n",
    "            \n",
    "            high_precision_display_answer,start_time_precision_display_invoke_model,end_time_precision_display_invoke_model=generate_predictions(text_for_prompt=prompt_precision_display_data,model_params=model_params,modelID=modelID,accept=accept,contentType=contentType,model_type=model_type,question=question,prompt_type=prompt_type)\n",
    "            \n",
    "            high_recall_answer,start_time_recall_display_invoke_model,end_time_recall_display_invoke_model=generate_predictions(text_for_prompt=masterfile_json[question][filenames][\"context\"][\"high recall\"],model_params=model_params,modelID=modelID,accept=accept,contentType=contentType,model_type=model_type,question=question,prompt_type=prompt_type)\n",
    "            \n",
    "            prediction_key_count=len([filenames_key for filenames_key in masterfile_json[question][filenames].keys() if filenames_key.lower().startswith(\"predictions\")])\n",
    "            if len(masterfile_json[question][filenames].keys())>1+prediction_key_count:\n",
    "                #human Answer\n",
    "                sme_name=[name for name in masterfile_json[question][filenames].keys() if name not in not_smename_key_list and name not in [filenames_key for filenames_key in masterfile_json[question][filenames].keys() if filenames_key.lower().startswith(\"predictions\")]]\n",
    "                human_answer=masterfile_json[question][filenames][sme_name[0]]\n",
    "                #Bert Score Predictions\n",
    "\n",
    "                bscore_precision_embed = bertscore.compute(predictions=[high_precision_embed_answer], references=[human_answer], lang=\"en\")\n",
    "                bscore_precision_display= bertscore.compute(predictions=[high_precision_display_answer], references=[human_answer], lang=\"en\")\n",
    "                bscore_recall = bertscore.compute(predictions=[high_recall_answer], references=[human_answer], lang=\"en\")\n",
    "                \n",
    "                #util.pytorch_cos_sim(model.encode(sentences[a], convert_to_tensor=True), model.encode(sentences[b], convert_to_tensor=True))\n",
    "                sscore_precision_embed = np.array(util.pytorch_cos_sim(model_similarity.encode(high_precision_embed_answer, convert_to_tensor=True), model_similarity.encode(human_answer, convert_to_tensor=True)))[0].tolist()\n",
    "                sscore_precision_display= np.array(util.pytorch_cos_sim(model_similarity.encode(high_precision_display_answer, convert_to_tensor=True), model_similarity.encode(human_answer, convert_to_tensor=True)))[0].tolist()\n",
    "                sscore_recall = np.array(util.pytorch_cos_sim(model_similarity.encode(high_recall_answer, convert_to_tensor=True), model_similarity.encode(human_answer, convert_to_tensor=True)))[0].tolist()\n",
    "                \n",
    "\n",
    "                #Stop Word and Verb Removal\n",
    "                human_answer_refined, high_precision_embed_answer_refined,\\\n",
    "                high_precision_display_answer_refined,high_recall_answer_refined=[stopword_verb_removal(sentence,nlp) for sentence in [human_answer, \n",
    "                                                                                    high_precision_embed_answer,\n",
    "                                                                                   high_precision_display_answer,\n",
    "                                                                                high_recall_answer]]\n",
    "\n",
    "\n",
    "                \n",
    "                bscore_precision_embed_refined = bertscore.compute(predictions=[high_precision_embed_answer_refined], references=[human_answer_refined], lang=\"en\")\n",
    "                bscore_precision_display_refined= bertscore.compute(predictions=[high_precision_display_answer_refined], references=[human_answer_refined], lang=\"en\")\n",
    "                bscore_recall_refined = bertscore.compute(predictions=[high_recall_answer_refined], references=[human_answer_refined], lang=\"en\")\n",
    "\n",
    "                sscore_precision_embed_refined = np.array(util.pytorch_cos_sim(model_similarity.encode(high_precision_embed_answer_refined, convert_to_tensor=True), model_similarity.encode(human_answer_refined, convert_to_tensor=True)))[0].tolist()\n",
    "                sscore_precision_display_refined= np.array(util.pytorch_cos_sim(model_similarity.encode(high_precision_display_answer_refined, convert_to_tensor=True), model_similarity.encode(human_answer_refined, convert_to_tensor=True)))[0].tolist()\n",
    "                sscore_recall_refined = np.array(util.pytorch_cos_sim(model_similarity.encode(high_recall_answer_refined, convert_to_tensor=True), model_similarity.encode(human_answer_refined, convert_to_tensor=True)))[0].tolist()\n",
    "                \n",
    "                \n",
    "            else:\n",
    "                bscore_precision_embed,bscore_precision_display,bscore_recall=-2,-2,-2\n",
    "                bscore_precision_embed_refined,bscore_precision_display_refined,bscore_recall_refined=-2,-2,-2\n",
    "                sscore_precision_embed,sscore_precision_display,sscore_recall=-2,-2,-2\n",
    "                sscore_precision_embed_refined,sscore_precision_display_refined,sscore_recall_refined=-2,-2,-2\n",
    "                human_answer_refined, high_precision_embed_answer_refined,\\\n",
    "                high_precision_display_answer_refined,high_recall_answer_refined=\"NA\",\"NA\",\"NA\",\"NA\"\n",
    "            \n",
    "            masterfile_json[question][filenames][prediction_tag]=dict()\n",
    "            masterfile_json[question][filenames][prediction_tag][\"embed - high precision\"]=high_precision_embed_answer\n",
    "            masterfile_json[question][filenames][prediction_tag][\"display - high precision\"]=high_precision_display_answer\n",
    "            masterfile_json[question][filenames][prediction_tag][\"high recall\"]=high_recall_answer\n",
    "            masterfile_json[question][filenames][prediction_tag][\"BScore embed - high precision\"]=bscore_precision_embed\n",
    "            masterfile_json[question][filenames][prediction_tag][\"BScore display - high precision\"]=bscore_precision_display\n",
    "            masterfile_json[question][filenames][prediction_tag][\"BScore high recall\"]=bscore_recall\n",
    "            masterfile_json[question][filenames][prediction_tag][\"Similarity Score - embed - high precision\"]=sscore_precision_embed\n",
    "            masterfile_json[question][filenames][prediction_tag][\"Similarity Score - display - high precision\"]=sscore_precision_display\n",
    "            masterfile_json[question][filenames][prediction_tag][\"Similarity Score - high recall\"]=sscore_recall\n",
    "            \n",
    "            masterfile_json[question][filenames][prediction_tag][\"stopword_verb_removed\"]=dict()\n",
    "            masterfile_json[question][filenames][prediction_tag][\"stopword_verb_removed\"][\"sme answer\"]=human_answer_refined\n",
    "            masterfile_json[question][filenames][prediction_tag][\"stopword_verb_removed\"][\"embed - high precision\"]=high_precision_embed_answer_refined\n",
    "            masterfile_json[question][filenames][prediction_tag][\"stopword_verb_removed\"][\"display - high precision\"]=high_precision_display_answer_refined\n",
    "            masterfile_json[question][filenames][prediction_tag][\"stopword_verb_removed\"][\"high recall\"]=high_recall_answer_refined\n",
    "            masterfile_json[question][filenames][prediction_tag][\"stopword_verb_removed\"][\"BScore embed - high precision\"]=bscore_precision_embed_refined\n",
    "            masterfile_json[question][filenames][prediction_tag][\"stopword_verb_removed\"][\"BScore display - high precision\"]=bscore_precision_display_refined\n",
    "            masterfile_json[question][filenames][prediction_tag][\"stopword_verb_removed\"][\"BScore high recall\"]=bscore_recall_refined\n",
    "            masterfile_json[question][filenames][prediction_tag][\"stopword_verb_removed\"][\"Similarity Score - embed - high precision\"]=sscore_precision_embed_refined\n",
    "            masterfile_json[question][filenames][prediction_tag][\"stopword_verb_removed\"][\"Similarity Score - display - high precision\"]=sscore_precision_display_refined\n",
    "            masterfile_json[question][filenames][prediction_tag][\"stopword_verb_removed\"][\"Similarity Score - high recall\"]=sscore_recall_refined\n",
    "            \n",
    "            \n",
    "            masterfile_json[question][filenames][prediction_tag][\"time\"]=dict()\n",
    "            masterfile_json[question][filenames][prediction_tag][\"time\"][\"embed - high precision\"]=end_time_precision_embed_invoke_model-start_time_precision_embed_invoke_model\n",
    "            masterfile_json[question][filenames][prediction_tag][\"time\"][\"display - high precision\"]=end_time_precision_display_invoke_model-start_time_precision_display_invoke_model\n",
    "            masterfile_json[question][filenames][prediction_tag][\"time\"][\"high recall\"]=end_time_recall_display_invoke_model-start_time_recall_display_invoke_model\n",
    "    return masterfile_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "58c35121-3d6b-4b98-ad5a-8a8bd01e8d06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/bert-base-uncased. Creating a new one with MEAN pooling.\n"
     ]
    }
   ],
   "source": [
    "model_similarity  = SentenceTransformer(\"bert-base-uncased\")\n",
    "not_smename_key_list=[\"context\"]\n",
    "\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a132672-d2e1-465e-bf2b-b7caeb1b3002",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# with open(\"../../data/BenefitsGQA/QA_output.json\") as file:\n",
    "with open(\"QA_output.json\") as file:\n",
    "    smefile_json=json.load(file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2de0b662-6c45-4652-8b18-98b7b2cf3a54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model_params={\"max_tokens_to_sample\": 120,\"temperature\":0}\n",
    "\n",
    "# prediction_tag=\"Predictions_falcon_40b\"\n",
    "# prompt_type=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7033e7a-1e04-43f3-aef2-c698b26f89fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do I need a precertification for imaging?\n",
      "Air Liquide USA - HMO Medical Plan SBC-South CA\n",
      "Chipotle - Chipotle Mexican Grill, Inc-174155-1J07-Preventive Plus w Anthem RX-20230101_20231231_SBC_en_\n",
      "Chipotle - EPO $0 Medical Plan SBC\n",
      "Chipotle - HSA $1500 Medical Plan SBC\n",
      "Chipotle - PPO $0 Rx Plan SBC\n",
      "Chipotle - PPO $2000 Medical Plan SBC-FL\n",
      "Chipotle - PPO $250 Medical Plan SBC\n",
      "Hey I got a uti, can I go to the ER and be covered?\n",
      "Air Liquide USA - HMO Medical Plan SBC-South CA\n",
      "Chipotle - Chipotle Mexican Grill, Inc-174155-1J07-Preventive Plus w Anthem RX-20230101_20231231_SBC_en_\n",
      "Chipotle - EPO $0 Medical Plan SBC\n",
      "Chipotle - HSA $1500 Medical Plan SBC\n",
      "Chipotle - PPO $0 Rx Plan SBC\n",
      "Chipotle - PPO $2000 Medical Plan SBC-FL\n",
      "Chipotle - PPO $250 Medical Plan SBC\n",
      "How are mental health visits covered?\n",
      "Air Liquide USA - HMO Medical Plan SBC-South CA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chipotle - Chipotle Mexican Grill, Inc-174155-1J07-Preventive Plus w Anthem RX-20230101_20231231_SBC_en_\n",
      "Chipotle - EPO $0 Medical Plan SBC\n",
      "Chipotle - HSA $1500 Medical Plan SBC\n",
      "Chipotle - PPO $0 Rx Plan SBC\n",
      "Chipotle - PPO $2000 Medical Plan SBC-FL\n",
      "Chipotle - PPO $250 Medical Plan SBC\n",
      "How are prescriptions covered?\n",
      "Air Liquide USA - HMO Medical Plan SBC-South CA\n",
      "Chipotle - Chipotle Mexican Grill, Inc-174155-1J07-Preventive Plus w Anthem RX-20230101_20231231_SBC_en_\n",
      "Chipotle - EPO $0 Medical Plan SBC\n",
      "Chipotle - HSA $1500 Medical Plan SBC\n",
      "Chipotle - PPO $0 Rx Plan SBC\n",
      "Chipotle - PPO $2000 Medical Plan SBC-FL\n",
      "Chipotle - PPO $250 Medical Plan SBC\n",
      "How are primary care office visits covered?\n",
      "Air Liquide USA - HMO Medical Plan SBC-South CA\n",
      "Chipotle - Chipotle Mexican Grill, Inc-174155-1J07-Preventive Plus w Anthem RX-20230101_20231231_SBC_en_\n",
      "Chipotle - EPO $0 Medical Plan SBC\n",
      "Chipotle - HSA $1500 Medical Plan SBC\n",
      "Chipotle - PPO $0 Rx Plan SBC\n",
      "Chipotle - PPO $2000 Medical Plan SBC-FL\n",
      "Chipotle - PPO $250 Medical Plan SBC\n",
      "How is a colonoscopy covered?\n",
      "Air Liquide USA - HMO Medical Plan SBC-South CA\n",
      "Chipotle - Chipotle Mexican Grill, Inc-174155-1J07-Preventive Plus w Anthem RX-20230101_20231231_SBC_en_\n",
      "Chipotle - EPO $0 Medical Plan SBC\n",
      "Chipotle - HSA $1500 Medical Plan SBC\n",
      "Chipotle - PPO $0 Rx Plan SBC\n",
      "Chipotle - PPO $2000 Medical Plan SBC-FL\n",
      "Chipotle - PPO $250 Medical Plan SBC\n",
      "How is durable medical equipment covered?\n",
      "Air Liquide USA - HMO Medical Plan SBC-South CA\n",
      "Chipotle - Chipotle Mexican Grill, Inc-174155-1J07-Preventive Plus w Anthem RX-20230101_20231231_SBC_en_\n",
      "Chipotle - EPO $0 Medical Plan SBC\n",
      "Chipotle - HSA $1500 Medical Plan SBC\n",
      "Chipotle - PPO $0 Rx Plan SBC\n",
      "Chipotle - PPO $2000 Medical Plan SBC-FL\n",
      "Chipotle - PPO $250 Medical Plan SBC\n",
      "How is lasik surgery covered?\n",
      "Air Liquide USA - HMO Medical Plan SBC-South CA\n",
      "Chipotle - Chipotle Mexican Grill, Inc-174155-1J07-Preventive Plus w Anthem RX-20230101_20231231_SBC_en_\n",
      "Chipotle - EPO $0 Medical Plan SBC\n",
      "Chipotle - HSA $1500 Medical Plan SBC\n",
      "Chipotle - PPO $0 Rx Plan SBC\n",
      "Chipotle - PPO $2000 Medical Plan SBC-FL\n",
      "Chipotle - PPO $250 Medical Plan SBC\n",
      "How is my bloodwork covered?\n",
      "Air Liquide USA - HMO Medical Plan SBC-South CA\n",
      "Chipotle - Chipotle Mexican Grill, Inc-174155-1J07-Preventive Plus w Anthem RX-20230101_20231231_SBC_en_\n",
      "Chipotle - EPO $0 Medical Plan SBC\n",
      "Chipotle - HSA $1500 Medical Plan SBC\n",
      "Chipotle - PPO $0 Rx Plan SBC\n",
      "Chipotle - PPO $2000 Medical Plan SBC-FL\n",
      "Chipotle - PPO $250 Medical Plan SBC\n",
      "How is physical therapy covered?\n",
      "Air Liquide USA - HMO Medical Plan SBC-South CA\n",
      "Chipotle - Chipotle Mexican Grill, Inc-174155-1J07-Preventive Plus w Anthem RX-20230101_20231231_SBC_en_\n",
      "Chipotle - EPO $0 Medical Plan SBC\n",
      "Chipotle - HSA $1500 Medical Plan SBC\n",
      "Chipotle - PPO $0 Rx Plan SBC\n",
      "Chipotle - PPO $2000 Medical Plan SBC-FL\n",
      "Chipotle - PPO $250 Medical Plan SBC\n",
      "How is telemedicine covered?\n",
      "Air Liquide USA - HMO Medical Plan SBC-South CA\n",
      "Chipotle - Chipotle Mexican Grill, Inc-174155-1J07-Preventive Plus w Anthem RX-20230101_20231231_SBC_en_\n",
      "Chipotle - EPO $0 Medical Plan SBC\n",
      "Chipotle - HSA $1500 Medical Plan SBC\n",
      "Chipotle - PPO $0 Rx Plan SBC\n",
      "Chipotle - PPO $2000 Medical Plan SBC-FL\n",
      "Chipotle - PPO $250 Medical Plan SBC\n",
      "How many physical therapy visits do I have?\n",
      "Air Liquide USA - HMO Medical Plan SBC-South CA\n",
      "Chipotle - Chipotle Mexican Grill, Inc-174155-1J07-Preventive Plus w Anthem RX-20230101_20231231_SBC_en_\n",
      "Chipotle - EPO $0 Medical Plan SBC\n",
      "Chipotle - HSA $1500 Medical Plan SBC\n",
      "Chipotle - PPO $0 Rx Plan SBC\n",
      "Chipotle - PPO $2000 Medical Plan SBC-FL\n",
      "Chipotle - PPO $250 Medical Plan SBC\n",
      "How much is covered with an Emergency Room visit?\n",
      "Air Liquide USA - HMO Medical Plan SBC-South CA\n",
      "Chipotle - Chipotle Mexican Grill, Inc-174155-1J07-Preventive Plus w Anthem RX-20230101_20231231_SBC_en_\n",
      "Chipotle - EPO $0 Medical Plan SBC\n",
      "Chipotle - HSA $1500 Medical Plan SBC\n",
      "Chipotle - PPO $0 Rx Plan SBC\n",
      "Chipotle - PPO $2000 Medical Plan SBC-FL\n",
      "Chipotle - PPO $250 Medical Plan SBC\n",
      "I'm looking to have a colonoscopy, how does where I get the surgery affect my coverage?\n",
      "Air Liquide USA - HMO Medical Plan SBC-South CA\n",
      "Chipotle - Chipotle Mexican Grill, Inc-174155-1J07-Preventive Plus w Anthem RX-20230101_20231231_SBC_en_\n",
      "Chipotle - EPO $0 Medical Plan SBC\n",
      "Chipotle - HSA $1500 Medical Plan SBC\n",
      "Chipotle - PPO $0 Rx Plan SBC\n",
      "Chipotle - PPO $2000 Medical Plan SBC-FL\n",
      "Chipotle - PPO $250 Medical Plan SBC\n",
      "What are urgent care benefits?\n",
      "Air Liquide USA - HMO Medical Plan SBC-South CA\n",
      "Chipotle - Chipotle Mexican Grill, Inc-174155-1J07-Preventive Plus w Anthem RX-20230101_20231231_SBC_en_\n",
      "Chipotle - EPO $0 Medical Plan SBC\n",
      "Chipotle - HSA $1500 Medical Plan SBC\n",
      "Chipotle - PPO $0 Rx Plan SBC\n",
      "Chipotle - PPO $2000 Medical Plan SBC-FL\n",
      "Chipotle - PPO $250 Medical Plan SBC\n",
      "What is my deductible?\n",
      "Air Liquide USA - HMO Medical Plan SBC-South CA\n",
      "Chipotle - Chipotle Mexican Grill, Inc-174155-1J07-Preventive Plus w Anthem RX-20230101_20231231_SBC_en_\n",
      "Chipotle - EPO $0 Medical Plan SBC\n",
      "Chipotle - HSA $1500 Medical Plan SBC\n",
      "Chipotle - PPO $0 Rx Plan SBC\n",
      "Chipotle - PPO $2000 Medical Plan SBC-FL\n",
      "Chipotle - PPO $250 Medical Plan SBC\n"
     ]
    }
   ],
   "source": [
    "error_message_list=[]\n",
    "message_token_counts_list=[]\n",
    "model_params={\"max_tokens_to_sample\": 120,\"temperature\":0.05}\n",
    "prediction_tag=\"Predictions_falcon_40b_v1\"\n",
    "modelID = 'hf-llm-falcon-40b-instruct-bf16-2023-09-19-01-54-52-766' # change this to use a different version from the model provider\n",
    "prompt_type=1\n",
    "model_type=\"jumpstart\"\n",
    "new_smefile_json=add_predictions(masterfile_json=smefile_json,model_params=model_params,modelID=modelID,accept=accept,\\\n",
    "                                 contentType=contentType,prediction_tag=prediction_tag,not_smename_key_list=not_smename_key_list,\\\n",
    "                                 model_type=model_type,nlp=nlp,prompt_type=prompt_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f5c4c08-cb27-4536-b3b9-de5499a5e5c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"predictions_withfalcon40B_v1_.json\",\"w\") as predictions_file:\n",
    "    json.dump(new_smefile_json,predictions_file, indent=4)\n",
    "    predictions_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e89113a0-28a8-4518-a1d5-53e7d5fab499",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do I need a precertification for imaging?\n",
      "Air Liquide USA - HMO Medical Plan SBC-South CA\n",
      "Chipotle - Chipotle Mexican Grill, Inc-174155-1J07-Preventive Plus w Anthem RX-20230101_20231231_SBC_en_\n",
      "Chipotle - EPO $0 Medical Plan SBC\n",
      "Chipotle - HSA $1500 Medical Plan SBC\n",
      "Chipotle - PPO $0 Rx Plan SBC\n",
      "Chipotle - PPO $2000 Medical Plan SBC-FL\n",
      "Chipotle - PPO $250 Medical Plan SBC\n",
      "Hey I got a uti, can I go to the ER and be covered?\n",
      "Air Liquide USA - HMO Medical Plan SBC-South CA\n",
      "Chipotle - Chipotle Mexican Grill, Inc-174155-1J07-Preventive Plus w Anthem RX-20230101_20231231_SBC_en_\n",
      "Chipotle - EPO $0 Medical Plan SBC\n",
      "Chipotle - HSA $1500 Medical Plan SBC\n",
      "Chipotle - PPO $0 Rx Plan SBC\n",
      "Chipotle - PPO $2000 Medical Plan SBC-FL\n",
      "Chipotle - PPO $250 Medical Plan SBC\n",
      "How are mental health visits covered?\n",
      "Air Liquide USA - HMO Medical Plan SBC-South CA\n",
      "Chipotle - Chipotle Mexican Grill, Inc-174155-1J07-Preventive Plus w Anthem RX-20230101_20231231_SBC_en_\n",
      "Chipotle - EPO $0 Medical Plan SBC\n",
      "Chipotle - HSA $1500 Medical Plan SBC\n",
      "Chipotle - PPO $0 Rx Plan SBC\n",
      "Chipotle - PPO $2000 Medical Plan SBC-FL\n",
      "Chipotle - PPO $250 Medical Plan SBC\n",
      "How are prescriptions covered?\n",
      "Air Liquide USA - HMO Medical Plan SBC-South CA\n",
      "Chipotle - Chipotle Mexican Grill, Inc-174155-1J07-Preventive Plus w Anthem RX-20230101_20231231_SBC_en_\n",
      "Chipotle - EPO $0 Medical Plan SBC\n",
      "Chipotle - HSA $1500 Medical Plan SBC\n",
      "Chipotle - PPO $0 Rx Plan SBC\n",
      "Chipotle - PPO $2000 Medical Plan SBC-FL\n",
      "Chipotle - PPO $250 Medical Plan SBC\n",
      "How are primary care office visits covered?\n",
      "Air Liquide USA - HMO Medical Plan SBC-South CA\n",
      "Chipotle - Chipotle Mexican Grill, Inc-174155-1J07-Preventive Plus w Anthem RX-20230101_20231231_SBC_en_\n",
      "Chipotle - EPO $0 Medical Plan SBC\n",
      "Chipotle - HSA $1500 Medical Plan SBC\n",
      "Chipotle - PPO $0 Rx Plan SBC\n",
      "Chipotle - PPO $2000 Medical Plan SBC-FL\n",
      "Chipotle - PPO $250 Medical Plan SBC\n",
      "How is a colonoscopy covered?\n",
      "Air Liquide USA - HMO Medical Plan SBC-South CA\n",
      "Chipotle - Chipotle Mexican Grill, Inc-174155-1J07-Preventive Plus w Anthem RX-20230101_20231231_SBC_en_\n",
      "Chipotle - EPO $0 Medical Plan SBC\n",
      "Chipotle - HSA $1500 Medical Plan SBC\n",
      "Chipotle - PPO $0 Rx Plan SBC\n",
      "Chipotle - PPO $2000 Medical Plan SBC-FL\n",
      "Chipotle - PPO $250 Medical Plan SBC\n",
      "How is durable medical equipment covered?\n",
      "Air Liquide USA - HMO Medical Plan SBC-South CA\n",
      "Chipotle - Chipotle Mexican Grill, Inc-174155-1J07-Preventive Plus w Anthem RX-20230101_20231231_SBC_en_\n",
      "Chipotle - EPO $0 Medical Plan SBC\n",
      "Chipotle - HSA $1500 Medical Plan SBC\n",
      "Chipotle - PPO $0 Rx Plan SBC\n",
      "Chipotle - PPO $2000 Medical Plan SBC-FL\n",
      "Chipotle - PPO $250 Medical Plan SBC\n",
      "How is lasik surgery covered?\n",
      "Air Liquide USA - HMO Medical Plan SBC-South CA\n",
      "Chipotle - Chipotle Mexican Grill, Inc-174155-1J07-Preventive Plus w Anthem RX-20230101_20231231_SBC_en_\n",
      "Chipotle - EPO $0 Medical Plan SBC\n",
      "Chipotle - HSA $1500 Medical Plan SBC\n",
      "Chipotle - PPO $0 Rx Plan SBC\n",
      "Chipotle - PPO $2000 Medical Plan SBC-FL\n",
      "Chipotle - PPO $250 Medical Plan SBC\n",
      "How is my bloodwork covered?\n",
      "Air Liquide USA - HMO Medical Plan SBC-South CA\n",
      "Chipotle - Chipotle Mexican Grill, Inc-174155-1J07-Preventive Plus w Anthem RX-20230101_20231231_SBC_en_\n",
      "Chipotle - EPO $0 Medical Plan SBC\n",
      "Chipotle - HSA $1500 Medical Plan SBC\n",
      "Chipotle - PPO $0 Rx Plan SBC\n",
      "Chipotle - PPO $2000 Medical Plan SBC-FL\n",
      "Chipotle - PPO $250 Medical Plan SBC\n",
      "How is physical therapy covered?\n",
      "Air Liquide USA - HMO Medical Plan SBC-South CA\n",
      "Chipotle - Chipotle Mexican Grill, Inc-174155-1J07-Preventive Plus w Anthem RX-20230101_20231231_SBC_en_\n",
      "Chipotle - EPO $0 Medical Plan SBC\n",
      "Chipotle - HSA $1500 Medical Plan SBC\n",
      "Chipotle - PPO $0 Rx Plan SBC\n",
      "Chipotle - PPO $2000 Medical Plan SBC-FL\n",
      "Chipotle - PPO $250 Medical Plan SBC\n",
      "How is telemedicine covered?\n",
      "Air Liquide USA - HMO Medical Plan SBC-South CA\n",
      "Chipotle - Chipotle Mexican Grill, Inc-174155-1J07-Preventive Plus w Anthem RX-20230101_20231231_SBC_en_\n",
      "Chipotle - EPO $0 Medical Plan SBC\n",
      "Chipotle - HSA $1500 Medical Plan SBC\n",
      "Chipotle - PPO $0 Rx Plan SBC\n",
      "Chipotle - PPO $2000 Medical Plan SBC-FL\n",
      "Chipotle - PPO $250 Medical Plan SBC\n",
      "How many physical therapy visits do I have?\n",
      "Air Liquide USA - HMO Medical Plan SBC-South CA\n",
      "Chipotle - Chipotle Mexican Grill, Inc-174155-1J07-Preventive Plus w Anthem RX-20230101_20231231_SBC_en_\n",
      "Chipotle - EPO $0 Medical Plan SBC\n",
      "Chipotle - HSA $1500 Medical Plan SBC\n",
      "Chipotle - PPO $0 Rx Plan SBC\n",
      "Chipotle - PPO $2000 Medical Plan SBC-FL\n",
      "Chipotle - PPO $250 Medical Plan SBC\n",
      "How much is covered with an Emergency Room visit?\n",
      "Air Liquide USA - HMO Medical Plan SBC-South CA\n",
      "Chipotle - Chipotle Mexican Grill, Inc-174155-1J07-Preventive Plus w Anthem RX-20230101_20231231_SBC_en_\n",
      "Chipotle - EPO $0 Medical Plan SBC\n",
      "Chipotle - HSA $1500 Medical Plan SBC\n",
      "Chipotle - PPO $0 Rx Plan SBC\n",
      "Chipotle - PPO $2000 Medical Plan SBC-FL\n",
      "Chipotle - PPO $250 Medical Plan SBC\n",
      "I'm looking to have a colonoscopy, how does where I get the surgery affect my coverage?\n",
      "Air Liquide USA - HMO Medical Plan SBC-South CA\n",
      "Chipotle - Chipotle Mexican Grill, Inc-174155-1J07-Preventive Plus w Anthem RX-20230101_20231231_SBC_en_\n",
      "Chipotle - EPO $0 Medical Plan SBC\n",
      "Chipotle - HSA $1500 Medical Plan SBC\n",
      "Chipotle - PPO $0 Rx Plan SBC\n",
      "Chipotle - PPO $2000 Medical Plan SBC-FL\n",
      "Chipotle - PPO $250 Medical Plan SBC\n",
      "What are urgent care benefits?\n",
      "Air Liquide USA - HMO Medical Plan SBC-South CA\n",
      "Chipotle - Chipotle Mexican Grill, Inc-174155-1J07-Preventive Plus w Anthem RX-20230101_20231231_SBC_en_\n",
      "Chipotle - EPO $0 Medical Plan SBC\n",
      "Chipotle - HSA $1500 Medical Plan SBC\n",
      "Chipotle - PPO $0 Rx Plan SBC\n",
      "Chipotle - PPO $2000 Medical Plan SBC-FL\n",
      "Chipotle - PPO $250 Medical Plan SBC\n",
      "What is my deductible?\n",
      "Air Liquide USA - HMO Medical Plan SBC-South CA\n",
      "Chipotle - Chipotle Mexican Grill, Inc-174155-1J07-Preventive Plus w Anthem RX-20230101_20231231_SBC_en_\n",
      "Chipotle - EPO $0 Medical Plan SBC\n",
      "Chipotle - HSA $1500 Medical Plan SBC\n",
      "Chipotle - PPO $0 Rx Plan SBC\n",
      "Chipotle - PPO $2000 Medical Plan SBC-FL\n",
      "Chipotle - PPO $250 Medical Plan SBC\n"
     ]
    }
   ],
   "source": [
    "error_message_list=[]\n",
    "message_token_counts_list=[]\n",
    "model_params= {\n",
    "        \"do_sample\": True,\n",
    "        \"top_p\": 0.999999,\n",
    "        \"temperature\": 0.01,\n",
    "        \"max_new_tokens\": 120,\n",
    "        #\"stop\": [\"<|endoftext|>\", \"</s>\"]\n",
    "    }\n",
    "prediction_tag=\"Predictions_falcon_40b_v2\"\n",
    "modelID = 'hf-llm-falcon-40b-instruct-bf16-2023-09-19-01-54-52-766' # change this to use a different version from the model provider\n",
    "prompt_type=1\n",
    "model_type=\"jumpstart\"\n",
    "new_smefile_json=add_predictions(masterfile_json=new_smefile_json,model_params=model_params,modelID=modelID,accept=accept,\\\n",
    "                                 contentType=contentType,prediction_tag=prediction_tag,not_smename_key_list=not_smename_key_list,\\\n",
    "                                 model_type=model_type,nlp=nlp,prompt_type=prompt_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7460f78-afd6-48d5-a556-5c3f64cfa37a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"predictions_withfalcon40B_v2_.json\",\"w\") as predictions_file:\n",
    "    json.dump(new_smefile_json,predictions_file, indent=4)\n",
    "    predictions_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2008f4-4999-43fb-ac80-41122060b72b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae6dc3a-3fc8-40ec-b047-da3c3ea36372",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d861d671-c981-41d0-90d8-ad3c6717b9d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do I need a precertification for imaging?\n",
      "Air Liquide USA - HMO Medical Plan SBC-South CA\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_24/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">1445179117.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">27</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">model_response</span>                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_24/1445179117.py'</span>                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/sagemaker/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">predictor.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">161</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">predict</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">158 │   │   </span>request_args = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._create_request_args(                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">159 │   │   │   </span>data, initial_args, target_model, target_variant, inference_id                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">160 │   │   </span>)                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>161 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>response = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.sagemaker_session.sagemaker_runtime_client.invoke_endpoint(**req   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">162 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._handle_response(response)                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">163 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">164 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_handle_response</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, response):                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/botocore/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">client.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">535</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_api_call</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 532 │   │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\"{</span>py_operation_name<span style=\"color: #808000; text-decoration-color: #808000\">}() only accepts keyword arguments.\"</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 533 │   │   │   │   </span>)                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 534 │   │   │   # The \"self\" in this scope is referring to the BaseClient.</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 535 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._make_api_call(operation_name, kwargs)                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 536 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 537 │   │   </span>_api_call.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span> = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>(py_operation_name)                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 538 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/botocore/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">client.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">980</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_make_api_call</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 977 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> http.status_code &gt;= <span style=\"color: #0000ff; text-decoration-color: #0000ff\">300</span>:                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 978 │   │   │   </span>error_code = parsed_response.get(<span style=\"color: #808000; text-decoration-color: #808000\">\"Error\"</span>, {}).get(<span style=\"color: #808000; text-decoration-color: #808000\">\"Code\"</span>)                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 979 │   │   │   </span>error_class = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.exceptions.from_code(error_code)                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 980 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> error_class(parsed_response, operation_name)                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 981 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 982 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> parsed_response                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 983 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ModelError: </span>An error occurred <span style=\"font-weight: bold\">(</span>ModelError<span style=\"font-weight: bold\">)</span> when calling the InvokeEndpoint operation: Received client error <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">424</span><span style=\"font-weight: bold\">)</span> \n",
       "from primary with message \"<span style=\"font-weight: bold\">{</span>\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"code\"</span>:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">424</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"message\"</span>:<span style=\"color: #008000; text-decoration-color: #008000\">\"prediction failure\"</span>,\n",
       "  <span style=\"color: #008000; text-decoration-color: #008000\">\"error\"</span>:<span style=\"color: #008000; text-decoration-color: #008000\">\"Need to pass custom_attributes='accept_eula=true' as part of header. This means you have read and accept</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">the end-user license agreement (EULA) of the model. EULA can be found in model card description or from </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">https://ai.meta.com/resources/models-and-libraries/llama-downloads/.\"</span>\n",
       "<span style=\"font-weight: bold\">}</span>\". See \n",
       "<span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://us-east-1.console.aws.amazon.com/cloudwatch/home?region=us-east-1#logEventViewer:group=/aws/sagemaker/Endpo</span>\n",
       "<span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">ints/meta-textgeneration-llama-2-13b-f-2023-09-19-02-06-14-205</span> in account <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">110008799848</span> for more information.\n",
       "\n",
       "<span style=\"font-style: italic\">During handling of the above exception, another exception occurred:</span>\n",
       "\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_24/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">2662931221.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">9</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_24/2662931221.py'</span>                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_24/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">2503911413.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">20</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">add_predictions</span>                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_24/2503911413.py'</span>                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_24/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">2446944516.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">8</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">generate_predictions</span>                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_24/2446944516.py'</span>                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_24/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">1445179117.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">48</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">model_response</span>                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_24/1445179117.py'</span>                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ValueError: </span>invalid literal for <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">int</span><span style=\"font-weight: bold\">()</span> with base <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'rror'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_24/\u001b[0m\u001b[1;33m1445179117.py\u001b[0m:\u001b[94m27\u001b[0m in \u001b[92mmodel_response\u001b[0m                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_24/1445179117.py'\u001b[0m                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/sagemaker/\u001b[0m\u001b[1;33mpredictor.py\u001b[0m:\u001b[94m161\u001b[0m in \u001b[92mpredict\u001b[0m                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m158 \u001b[0m\u001b[2m│   │   \u001b[0mrequest_args = \u001b[96mself\u001b[0m._create_request_args(                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m159 \u001b[0m\u001b[2m│   │   │   \u001b[0mdata, initial_args, target_model, target_variant, inference_id                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m160 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m161 \u001b[2m│   │   \u001b[0mresponse = \u001b[96mself\u001b[0m.sagemaker_session.sagemaker_runtime_client.invoke_endpoint(**req   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m162 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._handle_response(response)                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m163 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m164 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_handle_response\u001b[0m(\u001b[96mself\u001b[0m, response):                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/botocore/\u001b[0m\u001b[1;33mclient.py\u001b[0m:\u001b[94m535\u001b[0m in \u001b[92m_api_call\u001b[0m                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 532 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m{\u001b[0mpy_operation_name\u001b[33m}\u001b[0m\u001b[33m() only accepts keyword arguments.\u001b[0m\u001b[33m\"\u001b[0m              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 533 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m)                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 534 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 535 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._make_api_call(operation_name, kwargs)                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 536 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 537 \u001b[0m\u001b[2m│   │   \u001b[0m_api_call.\u001b[91m__name__\u001b[0m = \u001b[96mstr\u001b[0m(py_operation_name)                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 538 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/botocore/\u001b[0m\u001b[1;33mclient.py\u001b[0m:\u001b[94m980\u001b[0m in \u001b[92m_make_api_call\u001b[0m                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 977 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m http.status_code >= \u001b[94m300\u001b[0m:                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 978 \u001b[0m\u001b[2m│   │   │   \u001b[0merror_code = parsed_response.get(\u001b[33m\"\u001b[0m\u001b[33mError\u001b[0m\u001b[33m\"\u001b[0m, {}).get(\u001b[33m\"\u001b[0m\u001b[33mCode\u001b[0m\u001b[33m\"\u001b[0m)                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 979 \u001b[0m\u001b[2m│   │   │   \u001b[0merror_class = \u001b[96mself\u001b[0m.exceptions.from_code(error_code)                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 980 \u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m error_class(parsed_response, operation_name)                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 981 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 982 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m parsed_response                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 983 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mModelError: \u001b[0mAn error occurred \u001b[1m(\u001b[0mModelError\u001b[1m)\u001b[0m when calling the InvokeEndpoint operation: Received client error \u001b[1m(\u001b[0m\u001b[1;36m424\u001b[0m\u001b[1m)\u001b[0m \n",
       "from primary with message \"\u001b[1m{\u001b[0m\n",
       "  \u001b[32m\"code\"\u001b[0m:\u001b[1;36m424\u001b[0m,\n",
       "  \u001b[32m\"message\"\u001b[0m:\u001b[32m\"prediction failure\"\u001b[0m,\n",
       "  \u001b[32m\"error\"\u001b[0m:\u001b[32m\"Need to pass \u001b[0m\u001b[32mcustom_attributes\u001b[0m\u001b[32m='\u001b[0m\u001b[32maccept_eula\u001b[0m\u001b[32m=\u001b[0m\u001b[32mtrue\u001b[0m\u001b[32m' as part of header. This means you have read and accept\u001b[0m\n",
       "\u001b[32mthe end-user license agreement \u001b[0m\u001b[32m(\u001b[0m\u001b[32mEULA\u001b[0m\u001b[32m)\u001b[0m\u001b[32m of the model. EULA can be found in model card description or from \u001b[0m\n",
       "\u001b[32mhttps://ai.meta.com/resources/models-and-libraries/llama-downloads/.\"\u001b[0m\n",
       "\u001b[1m}\u001b[0m\". See \n",
       "\u001b[4;94mhttps://us-east-1.console.aws.amazon.com/cloudwatch/home?\u001b[0m\u001b[4;94mregion\u001b[0m\u001b[4;94m=\u001b[0m\u001b[4;94mus\u001b[0m\u001b[4;94m-east-1#logEventViewer:\u001b[0m\u001b[4;94mgroup\u001b[0m\u001b[4;94m=/aws/sagemaker/Endpo\u001b[0m\n",
       "\u001b[4;94mints/meta-textgeneration-llama-2-13b-f-2023-09-19-02-06-14-205\u001b[0m in account \u001b[1;36m110008799848\u001b[0m for more information.\n",
       "\n",
       "\u001b[3mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
       "\n",
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_24/\u001b[0m\u001b[1;33m2662931221.py\u001b[0m:\u001b[94m9\u001b[0m in \u001b[92m<module>\u001b[0m                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_24/2662931221.py'\u001b[0m                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_24/\u001b[0m\u001b[1;33m2503911413.py\u001b[0m:\u001b[94m20\u001b[0m in \u001b[92madd_predictions\u001b[0m                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_24/2503911413.py'\u001b[0m                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_24/\u001b[0m\u001b[1;33m2446944516.py\u001b[0m:\u001b[94m8\u001b[0m in \u001b[92mgenerate_predictions\u001b[0m                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_24/2446944516.py'\u001b[0m                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_24/\u001b[0m\u001b[1;33m1445179117.py\u001b[0m:\u001b[94m48\u001b[0m in \u001b[92mmodel_response\u001b[0m                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_24/1445179117.py'\u001b[0m                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mValueError: \u001b[0minvalid literal for \u001b[1;35mint\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m with base \u001b[1;36m10\u001b[0m: \u001b[32m'rror'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# custom_attributes=\"accept_eula=true\" in predictor.predict(payload, custom_attributes=\"accept_eula=true\")\n",
    "error_message_list=[]\n",
    "message_token_counts_list=[]\n",
    "model_params={\"max_tokens_to_sample\": 120,\"temperature\":0.5}\n",
    "prediction_tag=\"Predictions_llama2_13b\"\n",
    "modelID = 'meta-textgeneration-llama-2-13b-f-2023-09-19-02-06-14-205' # change this to use a different version from the model provider\n",
    "prompt_type=1\n",
    "model_type=\"jumpstart\"\n",
    "new_smefile_json=add_predictions(masterfile_json=smefile_json,model_params=model_params,modelID=modelID,accept=accept,\\\n",
    "                                 contentType=contentType,prediction_tag=prediction_tag,not_smename_key_list=not_smename_key_list,\\\n",
    "                                 model_type=model_type,nlp=nlp,prompt_type=prompt_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc1a6b8-5ecc-485e-9378-0cbdb5962717",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"predictions_withllama2_13b_v1.json\",\"w\") as predictions_file:\n",
    "    json.dump(new_smefile_json,predictions_file, indent=4)\n",
    "    predictions_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b7b40b-7dbf-46a8-be4b-ebbe76174ada",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "error_message_list=[]\n",
    "message_token_counts_list=[]\n",
    "model_params= {\n",
    "        \"do_sample\": True,\n",
    "        \"top_p\": 0.999999,\n",
    "        \"temperature\": 0.01,\n",
    "        \"max_new_tokens\": 120,\n",
    "        #\"stop\": [\"<|endoftext|>\", \"</s>\"]\n",
    "    }\n",
    "prediction_tag=\"Predictions_llama2_13b_v2\"\n",
    "modelID = 'meta-textgeneration-llama-2-13b-f-2023-09-19-02-06-14-205' # change this to use a different version from the model provider\n",
    "prompt_type=1\n",
    "model_type=\"jumpstart\"\n",
    "new_smefile_json=add_predictions(masterfile_json=new_smefile_json,model_params=model_params,modelID=modelID,accept=accept,\\\n",
    "                                 contentType=contentType,prediction_tag=prediction_tag,not_smename_key_list=not_smename_key_list,\\\n",
    "                                 model_type=model_type,nlp=nlp,prompt_type=prompt_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e550531-4a50-49bb-8149-56e370d67896",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# error_message_list=[]\n",
    "# message_token_counts_list=[]\n",
    "# model_params={\"max_tokens_to_sample\": 120,\"temperature\":0}\n",
    "# prediction_tag=\"PredictionsBedrock_Prompt_Engg_2\"\n",
    "# modelID = 'anthropic.claude-v2' # change this to use a different version from the model provider\n",
    "# prompt_type=2\n",
    "# model_type=\"bedrock\"\n",
    "# new_smefile_json=add_predictions(masterfile_json=new_smefile_json,model_params=model_params,modelID=modelID,accept=accept,\\\n",
    "#                                  contentType=contentType,prediction_tag=prediction_tag,not_smename_key_list=not_smename_key_list,\\\n",
    "#                                  model_type=model_type,nlp=nlp,prompt_type=prompt_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ac895f-c558-4d67-bb1c-89624ca482c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"predictions_with_llama13b_v2.json\",\"w\") as predictions_file:\n",
    "    json.dump(new_smefile_json,predictions_file, indent=4)\n",
    "    predictions_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaffb88-167c-4dbc-95f2-901774956ea4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa47975-ce03-477d-92b6-b0e2fbf519c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026dfd71-8dd2-48fb-877d-4c0bd7e8b0f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f940f90-5aa0-4df9-93ee-261d686ededc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a026f54a-a2ae-4ff7-8b93-5b8f6d8b04d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 2.0.0 Python 3.10 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-2.0.0-cpu-py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
